{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Kx1J-D4Xx4sb",
        "bhe-MpTYJ0eB",
        "XNgKDSuHichx",
        "tEkGdAO-5l6_",
        "4BE5Fajy5ml4"
      ],
      "mount_file_id": "1AzTMYbkl7gZrlZvXJgu5abc3W8Hdelyv",
      "authorship_tag": "ABX9TyN1JiTk3cBK0HIJe22d2rrf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zeeshan138063/rag/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# RAG\n",
        "RAG (Retrieval-Augmented Generation) pipelines tackle AI hallucinations by integrating real-time information retrieval with text generation. This ensures that models produce more accurate, context-grounded responses, reducing the chances of misleading or incorrect outputs. A powerful step forward in building reliable AI!\n",
        "\n",
        "[More on RAG](https://www.linkedin.com/pulse/rag-retrieval-augmented-generation-pipelines-muhammad-zeeshan-oodvf/?trackingId=pXByMvHLQDW%2Fw11KVFg8LQ%3D%3D)\n",
        "\n",
        "\n",
        "\n",
        "1.   Ingestion\n",
        "2.   Retrieval\n",
        "3.   Synthesis\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o0FxhAllEP8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain\n",
        "***LangChain*** is a framework for developing applications powered by large language models (LLMs).\n",
        "by providing utilities for working with text, embeddings, memory, and more."
      ],
      "metadata": {
        "id": "Kx1J-D4Xx4sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YPPw3kwZHdZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5a939b-0f0e-44f2-d2a1-124c7db58946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.38 (from langchain)\n",
            "  Downloading langchain_core-0.2.38-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.115-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.38->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.16-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.2.38-py3-none-any.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.115-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, httpx, dataclasses-json, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.16 langchain-community-0.2.16 langchain-core-0.2.38 langchain-text-splitters-0.2.4 langsmith-0.1.115 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 tenacity-8.5.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document loaders [#](https://python.langchain.com/v0.2/docs/integrations/document_loaders/):\n",
        "\n",
        "---\n",
        "\n",
        "Loaders refer to components that are used to load or ingest data from various sources such as files, databases, APIs, or even web pages, and converting that data into a format that can be processed by LangChain.\n",
        "\n",
        "DocumentLoaders load data into the standard LangChain Document format.\n",
        "\n",
        "*Each DocumentLoader has its own specific parameters, but they can all be invoked in the same way with the ***.load*** method.*\n",
        "\n",
        "## Types of Loaders:\n",
        "\n",
        "\n",
        "*   **File Loaders:** These load data from files like text files, PDFs, CSVs, JSON, etc.\n",
        "\n",
        "*   **Database Loaders:** These load data from databases, converting rows or documents into a format that can be used by the language model.\n",
        "\n",
        "* **Web Loaders:** These scrape or fetch content from web pages, transforming the retrieved text into a structured format.\n",
        "\n",
        "* **API Loaders:** These fetch data from APIs and convert the responses into a usable format for further processing.\n",
        "\n",
        "* **Customization:**\n",
        " LangChain allows you to create custom loaders if your data source doesn’t fit the pre-existing loaders. This flexibility ensures you can integrate almost any data source into your language model application.\n",
        "\n",
        "\n",
        "###  Preprocessing:\n",
        "Loader performs necessary preprocessing steps such as tokenization, normalization and format conversiotn to ensure data is in the optimal state for model consumption\n",
        "\n",
        " ### Integration:\n",
        " Once the data is loaded, it can be passed through various components of LangChain, such as text splitting, embedding generation, memory integration, or directly into a language model for processing.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### Example Use Case\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "If you have a large set of PDF documents and you want to extract the text content for use in a language model application, you could use a PDF loader in LangChain to automate this process. The loader would read each PDF, extract the text, and format it in a way that the language model can use it for tasks like summarization, question answering, or information retrieval.\n",
        "\n",
        "Loaders are a crucial part of building data pipelines in LangChain, ensuring that data is efficiently and correctly ingested into the system for further processing."
      ],
      "metadata": {
        "id": "5X8H_xXU0oOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [PDF Loader](https://python.langchain.com/v0.2/docs/integrations/document_loaders/pypdfloader/)\n",
        "Lets load the PDF"
      ],
      "metadata": {
        "id": "bhe-MpTYJ0eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "JIAy51fTKECh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262d9299-85ee-40cc-ed71-907ee8281aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/295.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader #Initializatio\n",
        "file_path=\"/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "Bn8xlkO7KtIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Each page is a Document\n",
        "A Document contains text(page_content) and metadata."
      ],
      "metadata": {
        "id": "U_VnscLmNhez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "id": "sEdyLwzjN1oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page = pages[224]"
      ],
      "metadata": {
        "id": "1OtsVqAxN-Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page)"
      ],
      "metadata": {
        "id": "ElEw4kvjOHPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(page)"
      ],
      "metadata": {
        "id": "ccARxQ0bPUkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.metadata"
      ],
      "metadata": {
        "id": "S9RMojHlPclZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.page_content[0:10]"
      ],
      "metadata": {
        "id": "hFgL5mJDPhVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.json()"
      ],
      "metadata": {
        "id": "10jRbKG2P_Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compare 2 pages."
      ],
      "metadata": {
        "id": "QCVB6v0TQTCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pages[1]==pages[-1]"
      ],
      "metadata": {
        "id": "PehaAvCSQK-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While loading with\n",
        "\n",
        "```\n",
        " extract_images=True\n",
        "```\n",
        "Then I had to install following dependencies as well.\n"
      ],
      "metadata": {
        "id": "6O9Zq8bwHlme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime-gpu\n",
        "!pip install rapidocr-onnxruntime"
      ],
      "metadata": {
        "id": "OpNCEUOrHiSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b413b747-f1f7-4f55-f877-88f6bfcb0c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.13.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Downloading onnxruntime_gpu-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (226.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.2/226.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.19.2\n",
            "Collecting rapidocr-onnxruntime\n",
            "  Downloading rapidocr_onnxruntime-1.3.24-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyclipper>=1.2.0 (from rapidocr-onnxruntime)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (4.10.0.84)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.16.0)\n",
            "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (2.0.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (6.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (9.4.0)\n",
            "Collecting onnxruntime>=1.7.0 (from rapidocr-onnxruntime)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.13.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n",
            "Downloading rapidocr_onnxruntime-1.3.24-py3-none-any.whl (14.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyclipper, onnxruntime, rapidocr-onnxruntime\n",
            "Successfully installed onnxruntime-1.19.2 pyclipper-1.3.0.post5 rapidocr-onnxruntime-1.3.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf\", extract_images=True)\n",
        "# docs_lazy = loader.lazy_load()\n",
        "docs = await loader.aload()\n",
        "\n",
        "for doc in docs:\n",
        "    print(doc.page_content)\n",
        "    print(doc.metadata)\n",
        "    docs.append(doc)"
      ],
      "metadata": {
        "id": "Asn4fcrAHf5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Other Available Document Leaders ](https://python.langchain.com/v0.2/docs/integrations/document_loaders/#pdfs)\n",
        "\n",
        "\n",
        "1.  [PyPDF](https://python.langchain.com/v0.2/docs/integrations/document_loaders/pypdfloader)\n",
        " document loader  to load and parse PDFs\n",
        " > Supports PDFs\n",
        "\n",
        "2.   [Unstructured](https://python.langchain.com/v0.2/docs/integrations/document_loaders/unstructured_file)\n",
        " document loader to load files of many types.\n",
        " > Unstructured supports loading of text files, powerpoints, html, pdfs, images, and more\n",
        "3.   [Amazon Textract](https://python.langchain.com/v0.2/docs/integrations/document_loaders/amazon_textract/)\n",
        "Amazon Textract is a machine learning (ML) service that automatically extracts text, handwriting, and data from scanned documents.\n",
        "It goes beyond simple optical character recognition (OCR) to identify, understand, and extract data from forms and tables. Today, many companies manually extract data from scanned documents such as PDFs, images, tables, and forms, or through simple OCR software that requires manual configuration (which often must be updated when the form changes). To overcome these manual and expensive processes, Textract uses ML to read and process any type of document, accurately extracting text, handwriting, tables, and other data with no manual effort.\n",
        "> Textract supports PDF, TIFF, PNG and JPEG format.\n",
        "4.   [MathPix](https://python.langchain.com/v0.2/docs/integrations/document_loaders/mathpix/)\n",
        "Uses MathPix to laod PDFs\n",
        ">   Supports PDFs\n",
        "\n",
        "5.     [PDFPlumber](https://python.langchain.com/v0.2/docs/integrations/document_loaders/pdfplumber/) Like PyMuPDF, the output Documents contain detailed ***metadata about the PDF and its pages***, and returns one document per page.\n",
        ">   Supports PDFs\n",
        "6.   [PyPDFDirectry](https://python.langchain.com/v0.2/docs/integrations/document_loaders/pypdfdirectory)  loads all PDF files from a specific directory.\n",
        ">   Supports PDFs\n",
        "7.   [PyPDFium2](https://python.langchain.com/v0.2/docs/integrations/document_loaders/pypdfium2/)  Load PDF files using PyPDFium2.\n",
        ">   Supports PDFs\n",
        "8.    [UnstructuredPDFLoader](https://python.langchain.com/v0.2/docs/integrations/document_loaders/unstructured_pdfloader/)  Under the hood, Unstructured creates different \"elements\" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying mode=\"elements\"\n",
        ">   Supports PDFs\n",
        "9.   [PyMuPDF](https://python.langchain.com/v0.2/docs/integrations/document_loaders/pymupdf/PyMuPDF) is optimized for ***speed, and contains detailed metadata about the PDF and its pages.***   It returns one document per page.\n",
        "\n",
        "  >   Supports PDFs\n",
        "\n",
        "10.  [PDFMiner](https://python.langchain.com/v0.2/docs/integrations/document_loaders/pdfminer/)   Load PDF files using PDFMiner. Using PDFMiner to generate HTML text\n",
        ">   Supports PDFs\n",
        "\n",
        "\n",
        "all other PDF loaders can also be used to fetch remote PDFs\n",
        "We can update the built-in metadata and can add more information as per needed.\n",
        "\n"
      ],
      "metadata": {
        "id": "OlkfXnzrJ26k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are some useful examples by using the above mentioned Loaders"
      ],
      "metadata": {
        "id": "GpgxZDD4iIkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "id": "ZVKb_mlJS5T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PDFPlumberLoader\n",
        "\n",
        "loader = PDFPlumberLoader(\"/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf\")\n",
        "docs = loader.load()\n",
        "docs[0]"
      ],
      "metadata": {
        "id": "DU5hlB7aSocF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[4]"
      ],
      "metadata": {
        "id": "bO4d08V5ViwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d932e0-9e68-4e5e-eda5-b5c3356ae15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf', 'page': 4, 'total_pages': 241, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign CS6 (Macintosh)', 'producer': 'Adobe PDF Library 10.0.1', 'creationDate': \"D:20140328154719-07'00'\", 'modDate': \"D:20140328154734-07'00'\", 'trapped': ''}, page_content='If you purchase this book without a cover, or purchase a PDF, jpg, or tiff copy of this book, \\nit is likely stolen property or a counterfeit. In that case, neither the authors, the publisher, \\nnor any of their employees or agents has received any payment for the copy. Furthermore, \\ncounterfeiting is a known avenue of financial support for organized crime and terrorist \\ngroups. We urge you to please not purchase any such copy and to report any instance of \\nsomeone selling such copies to Plata Publishing LLC.\\nThis publication is designed to provide competent and reliable information regarding the \\nsubject matter covered. However, it is sold with the understanding that the author and \\npublisher are not engaged in rendering legal, financial, or other professional advice. Laws \\nand practices often vary from state to state and country to country and if legal or other \\nexpert assistance is required, the services of a professional should be sought. The author and \\npublisher specifically disclaim any liability that is incurred from the use or application of  \\nthe contents of this book.\\nCopyright © 2011 by CASHFLOW Technologies, Inc. All rights reserved. Except as \\npermitted under the U.S. Copyright Act of 1976, no part of this publication may be \\nreproduced, distributed, or transmitted in any form or by any means or stored in a  \\ndatabase or retrieval system, without the prior written permission of the publisher.\\nPublished by Plata Publishing, LLC\\t\\n\\t\\nCASHFLOW, Rich Dad, Rich Dad Advisors, ESBI, and are registered trademarks of \\nCASHFLOW Technologies, Inc.\\n\\t\\n        \\n\\t\\n\\t\\n             \\t \\t\\nare registered trademarks of \\n\\t\\n\\t\\n\\t\\n\\t\\nCASHFLOW Technologies, Inc.\\nPlata Publishing, LLC \\n4330 N. Civic Center Plaza \\nSuite 100 \\nScottsdale, AZ  85251 \\n(480) 998-6971\\nVisit our websites: PlataPublishing.com and RichDad.com \\t\\nPrinted in the United States of America\\n \\nFirst Edition: 1997\\nFirst Plata Publishing Edition: March 2011\\n032014\\nISBN: 978-1-61268-000-2 \\nCover photo credit: Seymour & Brody Studio\\nE\\nS\\nB\\nI\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured\n",
        "!pip install pillow-heif\n",
        "!pip install pi-heif # install the correct package\n",
        "!pip install unstructured[local-inference]\n"
      ],
      "metadata": {
        "id": "lnmjzk7lZo83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf\"\n",
        "loader = UnstructuredPDFLoader(file_path, mode=\"elements\")\n",
        "data = loader.load()\n",
        "data[0]\n"
      ],
      "metadata": {
        "id": "ef1yOrj2ZRWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime-gpu\n",
        "!pip install rapidocr-onnxruntime"
      ],
      "metadata": {
        "id": "wfT5CVCreTCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders import PyPDFLoader\n",
        "# loader = PyPDFLoader(\"/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf\")\n",
        "# pages = loader.load()\n",
        "docs = []\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf\", extract_images=True)\n",
        "# docs_lazy = loader.lazy_load()\n",
        "docs = await loader.aload()\n",
        "\n",
        "for doc in docs:\n",
        "    print(doc.page_content)\n",
        "    print(doc.metadata)\n",
        "    docs.append(doc)"
      ],
      "metadata": {
        "id": "UvrE15YZeTCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community pymupdf"
      ],
      "metadata": {
        "id": "kRIq4cCGb0P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(file_path=file_path)\n",
        "docs = loader.load()\n",
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLBlv2Veb3T3",
        "outputId": "fa81e4fa-61de-4576-db2d-05aed6cb1e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf', 'page': 0, 'total_pages': 241, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign CS6 (Macintosh)', 'producer': 'Adobe PDF Library 10.0.1', 'creationDate': \"D:20140328154719-07'00'\", 'modDate': \"D:20140328154734-07'00'\", 'trapped': ''}, page_content='Robert T. Kiyosaki\\nWhat The Rich Teach Their Kids About Money – \\nThat The Poor And Middle Class Do Not!\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQB29w_2c652",
        "outputId": "57f809ea-8910-435b-a7ac-13a6b42f2045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/Rich-Dad-Poor-Dad.pdf', 'page': 4, 'total_pages': 241, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign CS6 (Macintosh)', 'producer': 'Adobe PDF Library 10.0.1', 'creationDate': \"D:20140328154719-07'00'\", 'modDate': \"D:20140328154734-07'00'\", 'trapped': ''}, page_content='If you purchase this book without a cover, or purchase a PDF, jpg, or tiff copy of this book, \\nit is likely stolen property or a counterfeit. In that case, neither the authors, the publisher, \\nnor any of their employees or agents has received any payment for the copy. Furthermore, \\ncounterfeiting is a known avenue of financial support for organized crime and terrorist \\ngroups. We urge you to please not purchase any such copy and to report any instance of \\nsomeone selling such copies to Plata Publishing LLC.\\nThis publication is designed to provide competent and reliable information regarding the \\nsubject matter covered. However, it is sold with the understanding that the author and \\npublisher are not engaged in rendering legal, financial, or other professional advice. Laws \\nand practices often vary from state to state and country to country and if legal or other \\nexpert assistance is required, the services of a professional should be sought. The author and \\npublisher specifically disclaim any liability that is incurred from the use or application of  \\nthe contents of this book.\\nCopyright © 2011 by CASHFLOW Technologies, Inc. All rights reserved. Except as \\npermitted under the U.S. Copyright Act of 1976, no part of this publication may be \\nreproduced, distributed, or transmitted in any form or by any means or stored in a  \\ndatabase or retrieval system, without the prior written permission of the publisher.\\nPublished by Plata Publishing, LLC\\t\\n\\t\\nCASHFLOW, Rich Dad, Rich Dad Advisors, ESBI, and are registered trademarks of \\nCASHFLOW Technologies, Inc.\\n\\t\\n        \\n\\t\\n\\t\\n             \\t \\t\\nare registered trademarks of \\n\\t\\n\\t\\n\\t\\n\\t\\nCASHFLOW Technologies, Inc.\\nPlata Publishing, LLC \\n4330 N. Civic Center Plaza \\nSuite 100 \\nScottsdale, AZ  85251 \\n(480) 998-6971\\nVisit our websites: PlataPublishing.com and RichDad.com \\t\\nPrinted in the United States of America\\n \\nFirst Edition: 1997\\nFirst Plata Publishing Edition: March 2011\\n032014\\nISBN: 978-1-61268-000-2 \\nCover photo credit: Seymour & Brody Studio\\nE\\nS\\nB\\nI\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured[pdf]\n",
        "\n"
      ],
      "metadata": {
        "id": "7bitXePK31hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TrAgySeZ3m7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing with Urdu Language Documents"
      ],
      "metadata": {
        "id": "9aieIboj1wO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFium2Loader\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Ahtrame mahobt by farah tahir.pdf\"\n",
        "loader = PyPDFium2Loader(file_path)\n",
        "data = loader.load()\n",
        "for doc in data:\n",
        "  print(doc.page_content)\n",
        "  print(doc.metadata)"
      ],
      "metadata": {
        "id": "wAwQ3Ddq1vIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c1naTjCU199c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [CSV](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/csv/)\n",
        "A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.\n",
        "\n"
      ],
      "metadata": {
        "id": "XNgKDSuHichx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "file_path='/content/drive/MyDrive/Colab Notebooks/business-financial-data-march-2024-csv.csv'\n",
        "loader = CSVLoader(file_path)\n",
        "data = loader.load()\n",
        "for data in data[:2]: # load first 2 records\n",
        "  print(data.page_content)\n",
        "  print(data.metadata)"
      ],
      "metadata": {
        "id": "k08YTwyGeTCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7df3bdd-030d-4b22-ac22-851ec70e8424"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series_reference: BDCQ.SF1AA2CA\n",
            "Period: 2016.06\n",
            "Data_value: 1116.386\n",
            "Suppressed: \n",
            "STATUS: F\n",
            "UNITS: Dollars\n",
            "Magnitude: 6\n",
            "Subject: Business Data Collection - BDC\n",
            "Group: Industry by financial variable (NZSIOC Level 2)\n",
            "Series_title_1: Sales (operating income)\n",
            "Series_title_2: Forestry and Logging\n",
            "Series_title_3: Current prices\n",
            "Series_title_4: Unadjusted\n",
            "Series_title_5: \n",
            "{'source': '/content/drive/MyDrive/Colab Notebooks/business-financial-data-march-2024-csv.csv', 'row': 0}\n",
            "Series_reference: BDCQ.SF1AA2CA\n",
            "Period: 2016.09\n",
            "Data_value: 1070.874\n",
            "Suppressed: \n",
            "STATUS: F\n",
            "UNITS: Dollars\n",
            "Magnitude: 6\n",
            "Subject: Business Data Collection - BDC\n",
            "Group: Industry by financial variable (NZSIOC Level 2)\n",
            "Series_title_1: Sales (operating income)\n",
            "Series_title_2: Forestry and Logging\n",
            "Series_title_3: Current prices\n",
            "Series_title_4: Unadjusted\n",
            "Series_title_5: \n",
            "{'source': '/content/drive/MyDrive/Colab Notebooks/business-financial-data-march-2024-csv.csv', 'row': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can specify tge delimiter, fieldsname etc."
      ],
      "metadata": {
        "id": "WVz8AWyA8g61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loader = CSVLoader(file_path,\n",
        "                   csv_args={\n",
        "                       'delimiter': ',',\n",
        "                       'quotechar': '\"',\n",
        "                       'fieldnames': ['Series_reference', 'Period', 'STATUS', 'Data_value']\n",
        "                   })\n",
        "data = loader.load()\n",
        "for data in data[:2]: # load first 2 records\n",
        "  print(data.page_content)\n",
        "  print(data.metadata)"
      ],
      "metadata": {
        "id": "QnnvPHffeTCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31cfae40-2c53-43af-cd97-729ead8a3532"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series_reference: Series_reference\n",
            "Period: Period\n",
            "STATUS: Data_value\n",
            "Data_value: Suppressed\n",
            "None: STATUS,UNITS,Magnitude,Subject,Group,Series_title_1,Series_title_2,Series_title_3,Series_title_4,Series_title_5\n",
            "{'source': '/content/drive/MyDrive/Colab Notebooks/business-financial-data-march-2024-csv.csv', 'row': 0}\n",
            "Series_reference: BDCQ.SF1AA2CA\n",
            "Period: 2016.06\n",
            "STATUS: 1116.386\n",
            "Data_value: \n",
            "None: F,Dollars,6,Business Data Collection - BDC,Industry by financial variable (NZSIOC Level 2),Sales (operating income),Forestry and Logging,Current prices,Unadjusted,\n",
            "{'source': '/content/drive/MyDrive/Colab Notebooks/business-financial-data-march-2024-csv.csv', 'row': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**[Parameters](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.csv_loader.CSVLoader.html)**\n",
        "\n",
        "\n",
        " * **file_path** (Union[str, Path]) – The path to the CSV file.\n",
        "\n",
        "* **source_column** (Optional[str]) – The name of the column in the CSV file to use as the source. Optional. Defaults to None.\n",
        "\n",
        "* **metadata_columns** (Sequence[str]) – A sequence of column names to use as metadata. Optional.\n",
        "\n",
        "* **csv_args** (Optional[Dict]) – A dictionary of arguments to pass to the csv.DictReader. Optional. Defaults to None.\n",
        "\n",
        "* **encoding** (Optional[str]) – The encoding of the CSV file. Optional. Defaults to None.\n",
        "\n",
        "* **autodetect_encoding** (bool) – Whether to try to autodetect the file encoding.\n",
        "\n",
        "* **content_columns** (Sequence[str]) – A sequence of column names to use for the document content. If not present, use all columns that are not part of the metadata.\n"
      ],
      "metadata": {
        "id": "lN1jXj6F-Yc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(page)"
      ],
      "metadata": {
        "id": "SbG4XSc6eTCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(page)"
      ],
      "metadata": {
        "id": "Y9HaSS8ueTCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.metadata"
      ],
      "metadata": {
        "id": "vPKz5BjneTCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.page_content[0:10]"
      ],
      "metadata": {
        "id": "zDeJhrEKeTCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.json()"
      ],
      "metadata": {
        "id": "iIx547IOeTCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Webpages](https://python.langchain.com/v0.2/docs/integrations/document_loaders/#webpages)\n",
        "Lets load the Webpages\n",
        "\n",
        "This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.\n",
        "\n",
        "If you don't want to worry about website crawling, bypassing JS-blocking sites, and data cleaning, consider using FireCrawlLoader or the faster option SpiderLoader."
      ],
      "metadata": {
        "id": "lw5MIvU15k-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Available Webpage Leaders](https://python.langchain.com/v0.2/docs/integrations/document_loaders/#webpages)\n",
        "\n",
        "\n",
        "1.  [Web](https://python.langchain.com/v0.2/docs/integrations/document_loaders/web_base)\n",
        "Uses urllib and BeautifulSoup to load and parse HTML web pages.It will only get all the details of given url.\n",
        "\n",
        "2.   [RecursiveURL](https://python.langchain.com/v0.2/docs/integrations/document_loaders/recursive_url)\n",
        "Recursively scrapes all child links from a root URL\n",
        "\n",
        "3.   [Sitemap](https://python.langchain.com/v0.2/docs/integrations/document_loaders/sitemap)\n",
        "Scrapes all pages on a given sitemap\n",
        "\n",
        "4.   [Firecrawl](https://python.langchain.com/v0.2/docs/integrations/document_loaders/firecrawl)\n",
        "API service that can be deployed locally, hosted version has free credits."
      ],
      "metadata": {
        "id": "AaT99iUE5k-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_community beautifulsoup4"
      ],
      "metadata": {
        "id": "Rl06tZO35k-E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from pprint import pprint # import the pprint function from the standard library\n",
        "\n",
        "url=\"https://www.xevensolutions.com/\"\n",
        "# url=\"https://www.amazon.com/dp/B091GCJ4RT/\"\n",
        "# url=\"https://www.costco.co.uk/Garden-Sheds-Patio/Barbecues-and-Firepits/Gas-Barbecues/Kirkland-Signature-7-Burner-Mini-Island-Gas-Barbecue-Grill-Cover/p/2127649\"\n",
        "loader = WebBaseLoader(url)\n",
        "docs = loader.load()\n",
        "for doc in docs:\n",
        "  pprint(doc.page_content)\n",
        "  pprint(doc.metadata)"
      ],
      "metadata": {
        "id": "DjNOttjuBA5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We can also pass in a list of pages to load from.\n",
        "\n",
        "```\n",
        "loader_multiple_pages = WebBaseLoader([\"https://www.espn.com/\", \"https://google.com\"])\n",
        "```\n",
        "\n",
        "* we can pass proxies, bypass SSL verification and much more.\n",
        "* Load multiple urls concurrently\n",
        "** We can speed up the scraping process by scraping and parsing multiple urls concurrently.\n",
        "\n",
        "* * There are reasonable limits to concurrent requests, defaulting to 2 per second. If you aren't concerned about being a good citizen, or you control the server you are scraping and don't care about load, you can change the requests_per_second parameter to increase the max concurrent requests. Note, while this will speed up the scraping process, but may cause the server to block you. Be careful!\n",
        "\n",
        "\n",
        "* * ```\n",
        "loader.requests_per_second = 1\n",
        "```\n",
        "**Loading a xml file, or using a different BeautifulSoup parser**\n",
        "\n",
        "\n",
        "* * ```\n",
        "loader.default_parser = \"xml\"\n",
        "\n",
        "* ***Using proxies***\n",
        "* * Sometimes you might need to use proxies to get around IP blocks. You can pass in a dictionary of proxies to the loader (and requests underneath) to use them.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DNzPzrNCFXxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Webpages\n",
        "Lets load the Webpages"
      ],
      "metadata": {
        "id": "tEkGdAO-5l6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Available Webpage Leaders](https://python.langchain.com/v0.2/docs/integrations/document_loaders/#webpages)\n",
        "\n",
        "\n",
        "1.  [PyPDF](https://python.langchain.com/v0.2/docs/integrations/document_loaders/pypdfloader)\n",
        " document loader  to load and parse PDFs\n",
        " > Supports PDFs\n",
        "\n",
        "2.   [Unstructured](https://python.langchain.com/v0.2/docs/integrations/document_loaders/unstructured_file)\n",
        " document loader to load files of many types.\n",
        " > Unstructured supports loading of text files, powerpoints, html, pdfs, images, and more\n",
        "3.   [Amazon Textract](https://python.langchain.com/v0.2/docs/integrations/document_loaders/amazon_textract/)\n",
        "Amazon Textract is a machine learning (ML) service that automatically"
      ],
      "metadata": {
        "id": "k6d_8cpG5l7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "id": "QmbvYYk85l7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page = pages[224]"
      ],
      "metadata": {
        "id": "f4TfGlJ65l7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page)"
      ],
      "metadata": {
        "id": "OttETbuy5l7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(page)"
      ],
      "metadata": {
        "id": "701bUItH5l7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.metadata"
      ],
      "metadata": {
        "id": "MIPts5_R5l7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.page_content[0:10]"
      ],
      "metadata": {
        "id": "rIJBkDk05l7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.json()"
      ],
      "metadata": {
        "id": "RkxFhJ-n5l7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Webpages\n",
        "Lets load the Webpages"
      ],
      "metadata": {
        "id": "4BE5Fajy5ml4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Available Webpage Leaders](https://python.langchain.com/v0.2/docs/integrations/document_loaders/#webpages)\n",
        "\n",
        "\n",
        "1.  [PyPDF](https://python.langchain.com/v0.2/docs/integrations/document_loaders/pypdfloader)\n",
        " document loader  to load and parse PDFs\n",
        " > Supports PDFs\n",
        "\n",
        "2.   [Unstructured](https://python.langchain.com/v0.2/docs/integrations/document_loaders/unstructured_file)\n",
        " document loader to load files of many types.\n",
        " > Unstructured supports loading of text files, powerpoints, html, pdfs, images, and more\n",
        "3.   [Amazon Textract](https://python.langchain.com/v0.2/docs/integrations/document_loaders/amazon_textract/)\n",
        "Amazon Textract is a machine learning (ML) service that automatically"
      ],
      "metadata": {
        "id": "Y2evPQr85mmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "id": "mx3gE4V65mmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page = pages[224]"
      ],
      "metadata": {
        "id": "UKzUarTp5mmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page)"
      ],
      "metadata": {
        "id": "Hfj6IDK85mmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(page)"
      ],
      "metadata": {
        "id": "621-_kgm5mmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.metadata"
      ],
      "metadata": {
        "id": "rLjeXO1M5mmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.page_content[0:10]"
      ],
      "metadata": {
        "id": "o36jbyvM5mmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.json()"
      ],
      "metadata": {
        "id": "pK3rJiSS5mmH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}